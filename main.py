import pandas as pd
import glob
import os
import csv

folder_path = './'
output_file = 'merged_data.csv'

# –§—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
def detect_delimiter(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        sample = f.read(4096)
        sniffer = csv.Sniffer()
        dialect = sniffer.sniff(sample, delimiters=[',', '\t', ';', '|'])
    return dialect.delimiter

# –§—É–Ω–∫—Ü–∏—è —á—Ç–µ–Ω–∏—è JSON —Ñ–∞–π–ª–∞ –ø–æ —á–∞—Å—Ç—è–º
def json_chunk_reader(file, chunk_size=100000):
    data = pd.read_json(file, encoding='utf-8')
    for start in range(0, len(data), chunk_size):
        yield data.iloc[start:start + chunk_size]

file_handlers = {
    '.csv': lambda file: pd.read_csv(
        file,
        delimiter=detect_delimiter(file),
        chunksize=100000,
        encoding='utf-8',
        on_bad_lines='skip'
    ),
    '.json': lambda file: json_chunk_reader(file, chunk_size=100000),
    '.txt': lambda file: pd.read_csv(
        file,
        delimiter=detect_delimiter(file),
        chunksize=100000,
        encoding='utf-8',
        on_bad_lines='skip'
    )
}

# –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
output_file = 'merged_data.csv'
if os.path.exists(output_file):
    os.remove(output_file)

all_files = []
for ext in file_handlers.keys():
    all_files = glob.glob(os.path.join(folder_path, f'*{ext}'))
    all_files.extend(all_files)

total_files = len(all_files)
processed_files = 0

for file in all_files:
    ext = os.path.splitext(file)[1]
    handler = file_handlers[ext]

    try:
        file_size = os.path.getsize(file)
        bytes_read = 0
        print(f'üìÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {file}')

        for chunk in handler(file):
            if len(chunk.columns) == 1:
                # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–¥–∏–Ω–∏–ª–∏—Å—å –≤ –æ–¥–Ω—É –∫–æ–ª–æ–Ω–∫—É, —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
                delimiter = detect_delimiter(file)
                chunk = chunk.iloc[:, 0].str.split(delimiter, expand=True)

                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–º–µ–Ω–∞ —Å—Ç–æ–ª–±—Ü–æ–≤
                chunk.columns = ['bonus_card', 'full_name', 'email', 'phone', 'user_agent', 'date']

            # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ —Ñ–∞–π–ª–∞
            chunk['source_file'] = os.path.basename(file)

            # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ
            bytes_read += chunk.memory_usage(deep=True).sum()
            percent = min((bytes_read / file_size) * 100, 100)

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ CSV
            header = not os.path.exists(output_file)
            chunk.to_csv(output_file, mode='a', index=False, header=header, encoding='utf-8')

            print(f'   ‚îî‚îÄ –ü—Ä–æ–≥—Ä–µ—Å—Å —Ñ–∞–π–ª–∞ "{os.path.basename(file)}": {percent:.2f}%')

            del chunk  # –æ—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å

        processed_files += 1
        total_percent = (processed_files / total_files) * 100
        print(f'‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω —Ñ–∞–π–ª: {file} ({total_files}/{processed_files} —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ - {total_progress:.2f}%)\n')

    except Exception as e:
        print(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file}: {e}')

print('üöÄ –ì–æ—Ç–æ–≤–æ. –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫ merged_data.csv')
