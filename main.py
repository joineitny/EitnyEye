import pandas as pd
import glob
import os
import csv

folder_path = './'
output_file = 'merged_data.csv'

def detect_delimiter(file_path):
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
        header = file.readline()
        sniffer = csv.Sniffer()
        dialect = sniffer = csv.Sniffer().sniff(header, delimiters=[',', ';', '\t', '|'])
        return dialect.delimiter

def json_chunk_reader(file, chunk_size=100000):
    data = pd.read_json(file, encoding='utf-8')
    for start in range(0, len(data), chunk_size):
        yield data.iloc[start:start+chunk_size]

file_handlers = {
    '.csv': lambda file: pd.read_csv(
        file, 
        delimiter=detect_delimiter(file),
        chunksize=100000,
        encoding='utf-8',
        on_bad_lines='skip',
        low_memory=False
    ),
    '.json': lambda file: json_chunk_reader(file, chunk_size=100000),
    '.txt': lambda file: pd.read_csv(
        file, 
        delimiter=detect_delimiter(file), 
        chunksize=100000, 
        encoding='utf-8', 
        on_bad_lines='skip'
    )
}

if os.path.exists(output_file):
    os.remove(output_file)

files = [f for ext in file_handlers.keys() for f in glob.glob(os.path.join(folder_path, f'*{ext}'))]

processed_files = 0

for file in files:
    ext = os.path.splitext(file)[1]
    handler = file_handlers[ext]

    try:
        print(f'üìÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {file}')
        
        total_size = os.path.getsize(file)
        processed_size = 0

        for chunk in handler(file):
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø—Ä–∏ –∏—Ö –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏
            if len(chunk.columns) == 1:
                # –ü–æ–ø—ã—Ç–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã, –µ—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü
                sample = chunk.iloc[0, 0]
                detected_delim = ',' if ',' in sample else '\t'
                chunk = chunk.iloc[:, 0].str.split(detect_delimiter(file), expand=True)

                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–∏–º –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
                chunk.columns = ['bonus_card', 'full_name', 'email', 'phone', 'user_agent', 'date', 'source_file']

            else:
                chunk['source_file'] = os.path.basename(file)

            header = not os.path.exists(output_file)
            chunk.to_csv(output_file, mode='a', index=False, header=header, encoding='utf-8')

            processed_size += len(chunk.to_csv(index=False).encode('utf-8'))
            percent = min((processed_size / total_size) * 100, 100)
            print(f'   ‚îî‚îÄ –ü—Ä–æ–≥—Ä–µ—Å—Å: {percent:.2f}%')

            del chunk

        print(f'‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω —Ñ–∞–π–ª: {file}')

print('üöÄ –ì–æ—Ç–æ–≤–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç: merged_data.csv')
